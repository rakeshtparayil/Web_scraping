{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 1/5: https://ï»¿https://dubaihousekeeping.com/\n",
      "Scraping 2/5: https://elitemaids.ae/\n",
      "Scraping 3/5: https://justmaid.ae/\n",
      "Scraping 4/5: https://servicemarket.com/en/dubai/cleaning-maid-services\n",
      "Scraping 5/5: https://dubaiclean.com/\n",
      "\n",
      "Done! Results saved to 'meta_scraping_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# === Start of Script ===\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/Users/rakesh/Downloads/cleaning_company.csv\"              # Replace with your input CSV file\n",
    "    output_file = \"meta_scraping_results.csv\"\n",
    "\n",
    "    # Set up browser\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Read URLs from CSV\n",
    "    urls = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if row:\n",
    "                url = row[0].strip()\n",
    "                if not url.startswith(\"http\"):\n",
    "                    url = \"https://\" + url\n",
    "                urls.append(url)\n",
    "\n",
    "    # Scrape data\n",
    "    results = []\n",
    "    for i, url in enumerate(urls):\n",
    "        print(f\"Scraping {i + 1}/{len(urls)}: {url}\")\n",
    "        data = {\n",
    "            'url': url,\n",
    "            'title': '',\n",
    "            'meta_description': '',\n",
    "            'meta_keywords': '',\n",
    "            'status': 'success'\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "\n",
    "            data['title'] = driver.title\n",
    "\n",
    "            try:\n",
    "                desc = driver.find_element(By.XPATH, \"//meta[@name='description']\")\n",
    "                data['meta_description'] = desc.get_attribute('content')\n",
    "            except:\n",
    "                data['meta_description'] = 'Not found'\n",
    "\n",
    "            try:\n",
    "                keywords = driver.find_element(By.XPATH, \"//meta[@name='keywords']\")\n",
    "                data['meta_keywords'] = keywords.get_attribute('content')\n",
    "            except:\n",
    "                data['meta_keywords'] = 'Not found'\n",
    "\n",
    "        except Exception as e:\n",
    "            data['status'] = f'error: {str(e)}'\n",
    "\n",
    "        results.append(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=['url', 'title', 'meta_description', 'meta_keywords', 'status'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    # Close browser\n",
    "    driver.quit()\n",
    "    print(f\"\\nDone! Results saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "# SerpAPI key - either use the provided one or get from environment variable\n",
    "api_key = os.environ.get(\"SERPAPI_KEY\") or \"0dfdc537381f5983d131d9a92bd29f22a55ffdb8931bc36e2b0d99d848bd90fb\"\n",
    "\n",
    "# Set up the search parameters\n",
    "params = {\n",
    "    \"q\": \"Top Sights Paris\",\n",
    "    \"location\": \"Austin, Texas, United States\",\n",
    "    \"hl\": \"en\",\n",
    "    \"gl\": \"us\",\n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "# Perform the search\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "\n",
    "# Extract ads from the results\n",
    "ads = results.get(\"ads\", [])\n",
    "print(f\"Found {len(ads)} ads\")\n",
    "\n",
    "# Print information about the ads\n",
    "for i, ad in enumerate(ads, 1):\n",
    "    print(f\"Ad {i}: {ad.get('title')}\")\n",
    "    print(f\"  Link: {ad.get('link')}\")\n",
    "    print(f\"  Description: {ad.get('description', '')[:100]}...\")\n",
    "    \n",
    "    # Extract and print sitelinks if available\n",
    "    sitelinks = ad.get('sitelinks', [])\n",
    "    if sitelinks:\n",
    "        print(f\"  {len(sitelinks)} sitelinks:\")\n",
    "        for link in sitelinks:\n",
    "            print(f\"    - {link.get('title')}: {link.get('link')}\")\n",
    "    print()\n",
    "\n",
    "# Extract organic results\n",
    "organic_results = results.get(\"organic_results\", [])\n",
    "print(f\"Found {len(organic_results)} organic results\")\n",
    "\n",
    "# Extract places or top sights if available\n",
    "places_results = results.get(\"places_results\", []) or results.get(\"top_sights\", [])\n",
    "if places_results:\n",
    "    print(f\"Found {len(places_results)} places/top sights\")\n",
    "\n",
    "# Save the complete results to a JSON file\n",
    "output_file = \"paris_top_sights.json\"\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Example of how to access specific data\n",
    "print(\"\\nExample data extraction:\")\n",
    "if ads:\n",
    "    first_ad = ads[0]\n",
    "    print(f\"First ad position: {first_ad.get('position')}\")\n",
    "    print(f\"First ad block position: {first_ad.get('block_position')}\")\n",
    "    \n",
    "    # Additional fields in the first ad\n",
    "    fields_to_show = [\"title\", \"displayed_link\", \"tracking_link\", \"extensions\"]\n",
    "    for field in fields_to_show:\n",
    "        value = first_ad.get(field)\n",
    "        if isinstance(value, list):\n",
    "            print(f\"{field}: {', '.join(value)}\")\n",
    "        else:\n",
    "            print(f\"{field}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAB_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
